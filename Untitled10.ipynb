{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Trinhtrongtinh/OpenGL-Tutorials/blob/master/Untitled10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EgV-8kBxUbM"
      },
      "source": [
        "# Approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QP7zqd_sycO_"
      },
      "source": [
        "- Loading Data\n",
        "\n",
        "- Input and Output Data\n",
        "\n",
        "- Preprocessing image\n",
        "\n",
        "- Implement 2 model (Alexnet and VGG16)\n",
        "\n",
        "- Evaluate model\n",
        "\n",
        "- Show sample predict\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZVtbc-eQmpbn"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets, transforms\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "import os.path\n",
        "import os\n",
        "from collections import OrderedDict\n",
        "import argparse\n",
        "from torch import optim\n",
        "import json\n",
        "import torch.cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6H4oW3Bqpn4",
        "outputId": "df8208f8-1fd5-4979-da2b-cb16f879a89a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXvsY_2n3Oif"
      },
      "source": [
        "#DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "k2C7ZOcOpjpB"
      },
      "outputs": [],
      "source": [
        "def read_data(input_path):\n",
        "    folders = []\n",
        "    images = {}\n",
        "    count = 0\n",
        "\n",
        "    for root, dirs, files in os.walk(\"{}\".format(input_path)):\n",
        "\n",
        "        for name in dirs:\n",
        "            # print(\"folder name: \", name)\n",
        "            folders.append(name)\n",
        "            images[name] = []\n",
        "            # print(\"folder path: \", os.path.join(root, name))\n",
        "            # print(\"===========================================================================================\")\n",
        "\n",
        "        for name in files:\n",
        "            # print(\"file name: \", name)\n",
        "            name_path = os.path.join(root, name)\n",
        "            # print(\"file path: \", name_path)\n",
        "            if os.path.splitext(name)[1] == '.jpg' or os.path.splitext(name)[1] == '.png':\n",
        "                count += 1\n",
        "                split_path = name_path.split(\"/\")\n",
        "                image = name\n",
        "                # print(\"image name: \", image)\n",
        "                folder = split_path[-2]\n",
        "                # print(\"folder name: \", folder)\n",
        "                images[str(folder)].append(image)\n",
        "                # print(\"===========================================================================================\")\n",
        "\n",
        "    return folders, images, count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnloVBfbqfG8",
        "outputId": "045b86dd-c987-442b-93de-6a44e06d0938"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of train =  789\n"
          ]
        }
      ],
      "source": [
        "train_path = \"/content/drive/MyDrive/Colab Notebooks/DIP/datasets/recognition/train\"\n",
        "test_path = \"/content/drive/MyDrive/Colab Notebooks/DIP/datasets/recognition/test\"\n",
        "train_folders, train_images_dict, train_size = read_data(train_path)\n",
        "print(\"size of train = \", train_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "i0StCCcWpUZa"
      },
      "outputs": [],
      "source": [
        "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                       transforms.RandomResizedCrop(224),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       # transforms.Resize((224, 224)),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Resize((224, 224)),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms_le = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                          transforms.RandomResizedCrop(224),\n",
        "                                          transforms.RandomHorizontalFlip(),\n",
        "                                          # transforms.Resize((32, 32)),\n",
        "                                          transforms.ToTensor(),\n",
        "                                          transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "\n",
        "test_transforms_le = transforms.Compose([transforms.Resize((32, 32)),\n",
        "                                         transforms.ToTensor(),\n",
        "                                         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
      ],
      "metadata": {
        "id": "Cmtr2w0Us38n"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-rcRP03wcA02"
      },
      "outputs": [],
      "source": [
        "train_data = datasets.ImageFolder(train_path, transform=train_transforms)\n",
        "test_data = datasets.ImageFolder(test_path, transform=test_transforms)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_le = datasets.ImageFolder(train_path, transform=train_transforms_le)\n",
        "test_data_le = datasets.ImageFolder(test_path, transform=test_transforms_le)\n",
        "trainloader_le = torch.utils.data.DataLoader(train_data_le, batch_size=8, shuffle=True)\n",
        "testloader_le = torch.utils.data.DataLoader(test_data_le, batch_size=8)"
      ],
      "metadata": {
        "id": "ywHKEUOos8w5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWa-QkcB20_h"
      },
      "source": [
        "#Model VGG16\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NNXPQPQTpfsx"
      },
      "outputs": [],
      "source": [
        "class VGG16(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(VGG16, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            # 1\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "            # 2\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # 3\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "            # 4\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # 5\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "            # 6\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "            # 7\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # 8\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "            # 9\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "            # 10\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # 11\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "            # 12\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "            # 13\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            # nn.AvgPool2d(kernel_size=1, stride=1),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "        self.classifier = nn.Sequential(\n",
        "            # 14\n",
        "            nn.Linear(25088, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            # 15\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            # 16\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "        # self.classifier = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        #        print(out.shape)\n",
        "        out = self.avgpool(out)\n",
        "        #        print(out.shape)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.classifier(out)\n",
        "        #        print(out.shape)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODC-Avip3BB9"
      },
      "source": [
        "#Model Alexnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Kvx8j1VlpbQD"
      },
      "outputs": [],
      "source": [
        "\n",
        "class AlexNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 1000),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1000, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LeNet Model"
      ],
      "metadata": {
        "id": "yd7xszqosrHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        nn.Module.__init__(self)\n",
        "\n",
        "        self.feature_engineering = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3,\n",
        "                      out_channels=6,\n",
        "                      kernel_size=5),\n",
        "\n",
        "            nn.MaxPool2d(kernel_size=2,\n",
        "                         stride=2),\n",
        "\n",
        "            nn.Conv2d(in_channels=6,\n",
        "                      out_channels=16,\n",
        "                      kernel_size=5),\n",
        "\n",
        "            nn.MaxPool2d(kernel_size=2,\n",
        "                         stride=2)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(in_features=16 * 5 * 5,\n",
        "                      out_features=120),\n",
        "\n",
        "            nn.Linear(in_features=120,\n",
        "                      out_features=84),\n",
        "\n",
        "            nn.Linear(in_features=84,\n",
        "                      out_features=10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_engineering(x)\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "-TDUGedgson1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A68D6jXq-HHG"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bjhPQds4qcaw"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "test_losses = []\n",
        "train_accuracies = []\n",
        "test_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "w3I9Loqbpr51"
      },
      "outputs": [],
      "source": [
        "def deep_learning(model, trainloader, testloader, epochs, print_every, criterion, optimizer, device='cuda'):\n",
        "    epochs = epochs\n",
        "    print_every = print_every\n",
        "    steps = 0\n",
        "    model.to(device)\n",
        "\n",
        "    for e in range(epochs):\n",
        "        running_loss = 0\n",
        "        for ii, (inputs, labels) in enumerate(trainloader):\n",
        "            steps += 1\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            if steps % print_every == 0:\n",
        "                avg_train_loss = running_loss / print_every\n",
        "                train_losses.append(avg_train_loss)\n",
        "                print('EPOCHS : {}/{}'.format(e + 1, epochs),\n",
        "                      'Loss : {:.4f}'.format(avg_train_loss))\n",
        "\n",
        "                # Calculate and save test loss and accuracy\n",
        "                test_loss, test_accuracy = evaluate(model, testloader, criterion, device)\n",
        "                test_losses.append(test_loss)\n",
        "                test_accuracies.append(test_accuracy)\n",
        "\n",
        "                # Print and save test accuracy\n",
        "                print('Test Loss: {:.4f}'.format(test_loss),\n",
        "                      'Test Accuracy: {:.2f}%'.format(test_accuracy * 100))\n",
        "\n",
        "                # Calculate and save train accuracy\n",
        "                train_accuracy = evaluate(model, trainloader, criterion, device)[1]\n",
        "                train_accuracies.append(train_accuracy)\n",
        "\n",
        "                running_loss = 0\n",
        "\n",
        "    return train_losses, test_losses, train_accuracies, test_accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "L6TO0I7lp6FU"
      },
      "outputs": [],
      "source": [
        "def train(net, trainloader, testloader,name_model):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        net = net.cuda()\n",
        "\n",
        "    for param in net.parameters():\n",
        "        param.require_grad = False\n",
        "    if name_model == 'VGG16':\n",
        "      classifier_vgg = nn.Sequential(OrderedDict([\n",
        "          ('fc1', nn.Linear(25088, 4096)),\n",
        "          ('relu1', nn.ReLU()),\n",
        "          ('fc2', nn.Linear(4096, 1000)),\n",
        "          ('relu2', nn.ReLU()),\n",
        "          ('fc3', nn.Linear(1000, 10)),\n",
        "          ('output', nn.LogSoftmax(dim=1))\n",
        "      ]))\n",
        "      net.classifier = classifier_vgg\n",
        "\n",
        "    elif name_model == 'Alex':\n",
        "      classifier_alex = nn.Sequential(OrderedDict([\n",
        "          ('fc1', nn.Linear(256 * 6 * 6, 4096)),\n",
        "          ('relu1', nn.ReLU(inplace=True)),\n",
        "          ('fc2', nn.Linear(4096, 1000)),\n",
        "          ('relu2', nn.ReLU(inplace=True)),\n",
        "          ('fc3', nn.Linear(1000, 100)),\n",
        "          ('output', nn.LogSoftmax(dim=1))\n",
        "      ]))\n",
        "      net.classifier = classifier_alex\n",
        "\n",
        "    else:\n",
        "      classifier_le = nn.Sequential(OrderedDict([\n",
        "          ('fc1', nn.Linear(16 * 5 * 5, 120)),\n",
        "          ('relu1', nn.ReLU()),\n",
        "          ('fc2', nn.Linear(120, 84)),\n",
        "          ('relu2', nn.ReLU()),\n",
        "          ('fc3', nn.Linear(84, 100)),\n",
        "          ('output', nn.LogSoftmax(dim=1))\n",
        "      ]))\n",
        "      net.classifier = classifier_le\n",
        "\n",
        "    criterion = nn.NLLLoss()\n",
        "    optimizer = optim.Adam(net.classifier.parameters(), lr=0.001)\n",
        "\n",
        "    net.train()\n",
        "\n",
        "    deep_learning(net, trainloader, testloader, 40, 40, criterion, optimizer, 'cuda')\n",
        "    if name_model == 'VGG16':\n",
        "      network_saving(net,'pretrainvgg16.pth')\n",
        "    elif name_model == 'Alex':\n",
        "      network_saving(net,'pretrainalex.pth')\n",
        "    else:\n",
        "      network_saving(net,'pretrainle.pth')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMSRNXNn-fAX"
      },
      "source": [
        "##Train and evaluate VGG16 model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "oLR1AClJQcap"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "test_losses = []\n",
        "train_accuracies = []\n",
        "test_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "uznM6V8NpxOb"
      },
      "outputs": [],
      "source": [
        "def network_saving(model,name):\n",
        "    torch.save(model.state_dict(),name)\n",
        "    print('The Network is Saved')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "gd97D6pZouly"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, criterion, device='cuda'):\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_loss = running_loss / len(dataloader)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    return avg_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "ADPEbJrCdEoT",
        "outputId": "e822d3a2-50f7-4f8d-dd48-c07b7dbef31f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-1499a7923391>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvgg16_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg16_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'VGG16'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-d539ab26a0c8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, trainloader, testloader, name_model)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mdeep_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname_model\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'VGG16'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0mnetwork_saving\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'pretrainvgg16.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-2cebe6789e0c>\u001b[0m in \u001b[0;36mdeep_learning\u001b[0;34m(model, trainloader, testloader, epochs, print_every, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint_every\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1157\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1158\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ],
      "source": [
        "vgg16_model = VGG16()\n",
        "train(vgg16_model, trainloader, testloader,'VGG16')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zMZir9gpz8P"
      },
      "outputs": [],
      "source": [
        "def plot_loss_accuracy_VGG16(train_losses, test_losses, train_accuracies, test_accuracies, save_dir):\n",
        "    # Plot and save Loss\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    plt.plot(test_losses, label='Validation Loss')\n",
        "    plt.title('Loss Over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig(f'{save_dir}/loss_plot.png')\n",
        "    plt.show()\n",
        "\n",
        "    # Plot and save Accuracy\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_accuracies, label='Training Accuracy')\n",
        "    plt.plot(test_accuracies, label='Validation Accuracy')\n",
        "    plt.title('Accuracy Over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.savefig(f'{save_dir}/accuracy_plot.png')\n",
        "    plt.show()\n",
        "\n",
        "    # Save loss and accuracy values to text files\n",
        "    np.savetxt(f'{save_dir}/train_losses_VGG16.txt', train_losses)\n",
        "    np.savetxt(f'{save_dir}/test_losses_VGG16.txt', test_losses)\n",
        "    np.savetxt(f'{save_dir}/train_accuracies_VGG16.txt', train_accuracies)\n",
        "    np.savetxt(f'{save_dir}/test_accuracies_VGG16.txt', test_accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTrx18rMIY16"
      },
      "outputs": [],
      "source": [
        "plot_loss_accuracy_VGG16(train_losses, test_losses, train_accuracies, test_accuracies, '')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghd7JzsaHexU"
      },
      "source": [
        "##Train and evaluate Alexnet model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fezeFKuEbSjQ"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "test_losses = []\n",
        "train_accuracies = []\n",
        "test_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iWU5uuEHd0s"
      },
      "outputs": [],
      "source": [
        "Alex_model = AlexNet(num_classes=10)\n",
        "train(Alex_model, trainloader, testloader,'Alex')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2-ZrP6D1B8s"
      },
      "outputs": [],
      "source": [
        "def plot_loss_accuracy_ALEX(train_losses, test_losses, train_accuracies, test_accuracies, save_dir):\n",
        "    # Plot and save Loss\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    plt.plot(test_losses, label='Validation Loss')\n",
        "    plt.title('Loss Over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig(f'{save_dir}/loss_plot.png')\n",
        "    plt.show()\n",
        "\n",
        "    # Plot and save Accuracy\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_accuracies, label='Training Accuracy')\n",
        "    plt.plot(test_accuracies, label='Validation Accuracy')\n",
        "    plt.title('Accuracy Over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.savefig(f'{save_dir}/accuracy_plot.png')\n",
        "    plt.show()\n",
        "\n",
        "    # Save loss and accuracy values to text files\n",
        "    np.savetxt(f'{save_dir}/train_losses_AL.txt', train_losses)\n",
        "    np.savetxt(f'{save_dir}/test_losses_AL.txt', test_losses)\n",
        "    np.savetxt(f'{save_dir}/train_accuracies_AL.txt', train_accuracies)\n",
        "    np.savetxt(f'{save_dir}/test_accuracies_AL.txt', test_accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c15xU4DbIdPE"
      },
      "outputs": [],
      "source": [
        "plot_loss_accuracy_ALEX(train_losses, test_losses, train_accuracies, test_accuracies, '')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train and evaluate LeNet model"
      ],
      "metadata": {
        "id": "AbY2E0aotHh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "test_losses = []\n",
        "train_accuracies = []\n",
        "test_accuracies = []"
      ],
      "metadata": {
        "id": "E3u7e4CXtLSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Alex_model = AlexNet(num_classes=10)\n",
        "train(Alex_model, trainloader, testloader,'Le')"
      ],
      "metadata": {
        "id": "U5Hg1uz4tSgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss_accuracy_Le(train_losses, test_losses, train_accuracies, test_accuracies, save_dir):\n",
        "    # Plot and save Loss\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    plt.plot(test_losses, label='Validation Loss')\n",
        "    plt.title('Loss Over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig(f'{save_dir}/loss_plot.png')\n",
        "    plt.show()\n",
        "\n",
        "    # Plot and save Accuracy\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_accuracies, label='Training Accuracy')\n",
        "    plt.plot(test_accuracies, label='Validation Accuracy')\n",
        "    plt.title('Accuracy Over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.savefig(f'{save_dir}/accuracy_plot.png')\n",
        "    plt.show()\n",
        "\n",
        "    # Save loss and accuracy values to text files\n",
        "    np.savetxt(f'{save_dir}/train_losses_Le.txt', train_losses)\n",
        "    np.savetxt(f'{save_dir}/test_losses_Le.txt', test_losses)\n",
        "    np.savetxt(f'{save_dir}/train_accuracies_Le.txt', train_accuracies)\n",
        "    np.savetxt(f'{save_dir}/test_accuracies_Le.txt', test_accuracies)"
      ],
      "metadata": {
        "id": "CC_2T5wQtVGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_accuracy_Le(train_losses, test_losses, train_accuracies, test_accuracies, '')"
      ],
      "metadata": {
        "id": "Nc3E48jutXGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zz4vlAkeI1Ar"
      },
      "source": [
        "# Evaluation overall model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "It4MOjuEr-wg"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, dataloader, criterion):\n",
        "    model.eval()  # Chuyển sang chế độ đánh giá\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    predicted_labels = []\n",
        "    true_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "            predicted_labels.extend(predicted.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    average_loss = running_loss / len(dataloader)\n",
        "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "    precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
        "    recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "    print(f'Evaluation Results: Loss: {average_loss:.4f}, Accuracy: {accuracy:.4f}, F1-score: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}')\n",
        "\n",
        "    return average_loss, accuracy, f1, precision, recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8tQZnxpS9fW"
      },
      "outputs": [],
      "source": [
        "def pre_process_model(net,namemodel):\n",
        "    net = net.eval()\n",
        "\n",
        "    for param in net.parameters():\n",
        "        param.require_grad = False\n",
        "    if namemodel == 'VGG16':\n",
        "      classifier = nn.Sequential(OrderedDict([\n",
        "          ('fc1', nn.Linear(25088, 4096)),\n",
        "          ('relu1', nn.ReLU()),\n",
        "          ('fc2', nn.Linear(4096, 1000)),\n",
        "          ('relu2', nn.ReLU()),\n",
        "          ('fc3', nn.Linear(1000, 10)),\n",
        "          ('output', nn.LogSoftmax(dim=1))\n",
        "      ]))\n",
        "      net.classifier = classifier\n",
        "      network_loading(net, \"pretrainvgg16.pth\")\n",
        "\n",
        "    elif namemodel == 'Alex':\n",
        "      classifier_alex = nn.Sequential(OrderedDict([\n",
        "          ('fc1', nn.Linear(256 * 6 * 6, 4096)),\n",
        "          ('relu1', nn.ReLU(inplace=True)),\n",
        "          ('fc2', nn.Linear(4096, 1000)),\n",
        "          ('relu2', nn.ReLU(inplace=True)),\n",
        "          ('fc3', nn.Linear(1000, 100)),\n",
        "          ('output', nn.LogSoftmax(dim=1))\n",
        "      ]))\n",
        "      net.classifier = classifier_alex\n",
        "      network_loading(net, \"pretrainalex.pth\")\n",
        "\n",
        "    else:\n",
        "      classifier_le = nn.Sequential(OrderedDict([\n",
        "          ('fc1', nn.Linear(16 * 5 * 5, 120)),\n",
        "          ('relu1', nn.ReLU()),\n",
        "          ('fc2', nn.Linear(120, 84)),\n",
        "          ('relu2', nn.ReLU()),\n",
        "          ('fc3', nn.Linear(84, 100)),\n",
        "          ('output', nn.LogSoftmax(dim=1))\n",
        "      ]))\n",
        "      net.classifier = classifier_le\n",
        "      network_loading(net, \"pretrainle.pth\")\n",
        "    return net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFq0DGN1Xna0"
      },
      "source": [
        "- Evaluate VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aF1r9LVwSIpM"
      },
      "outputs": [],
      "source": [
        "vgg16_model = VGG16()\n",
        "vgg16 = pre_process_model(vgg16_model,'VGG16')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "evaluate_model(vgg16, testloader, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7Ai5cRPXxHR"
      },
      "source": [
        "- Evaluate Alexnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_rmEhpoX1Ps"
      },
      "outputs": [],
      "source": [
        "Alex_model = AlexNet(num_classes=10)\n",
        "Alex = pre_process_model(Alex_model,'Alex')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "evaluate_model(Alex, testloader, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Evaluate LeNet"
      ],
      "metadata": {
        "id": "CjZB9TgFuZyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Le_model = LeNet(num_classes=10)\n",
        "Le = pre_process_model(Le_model,'Le')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "evaluate_model(Le, testloader, criterion)"
      ],
      "metadata": {
        "id": "5zNKUUYqueD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHAcaAgaIrng"
      },
      "source": [
        "#Predict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBNpcRZ4pvWN"
      },
      "outputs": [],
      "source": [
        "def network_loading(model, ckp_path):\n",
        "    state_dict = torch.load(ckp_path)\n",
        "    model.load_state_dict(state_dict)\n",
        "    print('The Network is Loaded')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIMAdVJrpy7N"
      },
      "outputs": [],
      "source": [
        "def process_image(image):\n",
        "    pic = Image.open(image)\n",
        "    return process_pic(pic)\n",
        "\n",
        "\n",
        "def process_pic(pic):\n",
        "    pic = pic.resize((224, 224))\n",
        "\n",
        "    mean = [0.485, 0.456, 0.406]\n",
        "    std = [0.229, 0.224, 0.225]\n",
        "    np_image = np.array(pic)\n",
        "    np_image = np_image / 255\n",
        "\n",
        "    for i in range(2):\n",
        "        np_image[:, :, i] -= mean[i]\n",
        "        np_image[:, :, i] /= std[i]\n",
        "\n",
        "    np_image = np_image.transpose((2, 0, 1))\n",
        "    np_image = torch.from_numpy(np_image)\n",
        "    np_image = np_image.float()\n",
        "    np_image = np_image.type(torch.FloatTensor)\n",
        "    np_image = np_image.cuda()\n",
        "    return np_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uy-o_NWPp2Is"
      },
      "outputs": [],
      "source": [
        "def predict(image_path, model, topk=3):\n",
        "    if torch.cuda.is_available():\n",
        "        model = model.cuda()\n",
        "    img = process_image(image_path)\n",
        "    return predict_pic(img, model, topk)\n",
        "\n",
        "\n",
        "def predict_pic(img, model, topk=3, need_cuda=False):\n",
        "    img = img.unsqueeze(0)\n",
        "    img = img.cuda()\n",
        "\n",
        "    if need_cuda:\n",
        "        model = model.to(\"cuda\")\n",
        "\n",
        "    result = model(img).topk(topk)\n",
        "    probs = []\n",
        "    classes = []\n",
        "    a = result[0]\n",
        "    b = result[1].tolist()\n",
        "\n",
        "    for i in a[0]:\n",
        "        probs.append(torch.exp(i).tolist())\n",
        "    for n in b[0]:\n",
        "        classes.append(str(n + 1))\n",
        "\n",
        "    return (probs, classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NggIvLjwp-kn"
      },
      "outputs": [],
      "source": [
        "def test(net,namemodel):\n",
        "    net = net.eval()\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        net = net.cuda()\n",
        "\n",
        "    for param in net.parameters():\n",
        "        param.require_grad = False\n",
        "    if namemodel == 'VGG16':\n",
        "      classifier_vgg = nn.Sequential(OrderedDict([\n",
        "          ('fc1', nn.Linear(25088, 4096)),\n",
        "          ('relu1', nn.ReLU()),\n",
        "          ('fc2', nn.Linear(4096, 1000)),\n",
        "          ('relu2', nn.ReLU()),\n",
        "          ('fc3', nn.Linear(1000, 10)),\n",
        "          ('output', nn.LogSoftmax(dim=1))\n",
        "      ]))\n",
        "      net.classifier = classifier_vgg\n",
        "      network_loading(net, 'pretrainvgg16.pth')\n",
        "    elif namemodel == 'Alex':\n",
        "      classifier_alex = nn.Sequential(OrderedDict([\n",
        "          ('fc1', nn.Linear(256 * 6 * 6, 4096)),\n",
        "          ('relu1', nn.ReLU(inplace=True)),\n",
        "          ('fc2', nn.Linear(4096, 1000)),\n",
        "          ('relu2', nn.ReLU(inplace=True)),\n",
        "          ('fc3', nn.Linear(1000, 100)),\n",
        "          ('output', nn.LogSoftmax(dim=1))\n",
        "      ]))\n",
        "      net.classifier = classifier_alex\n",
        "      network_loading(net, 'pretrainalex.pth')\n",
        "\n",
        "    else:\n",
        "      classifier_le = nn.Sequential(OrderedDict([\n",
        "          ('fc1', nn.Linear(16 * 5 * 5, 120)),\n",
        "          ('relu1', nn.ReLU()),\n",
        "          ('fc2', nn.Linear(120, 84)),\n",
        "          ('relu2', nn.ReLU()),\n",
        "          ('fc3', nn.Linear(84, 100)),\n",
        "          ('output', nn.LogSoftmax(dim=1))\n",
        "      ]))\n",
        "      net.classifier = classifier_le\n",
        "      network_loading(net, 'pretrainle.pth')\n",
        "\n",
        "    dir_pic = '/content/drive/MyDrive/Colab Notebooks/DIP/datasets/sample2.jpg'\n",
        "    result = predict(dir_pic, net, 3)\n",
        "    probs = result[0]\n",
        "    classes = result[1]\n",
        "    print(\"classes = \", classes)\n",
        "\n",
        "    with open('cat_to_name.json', 'r') as f:\n",
        "        cat_to_name = json.load(f)\n",
        "\n",
        "    names = []\n",
        "    for i in classes:\n",
        "        names.append(cat_to_name[i])\n",
        "\n",
        "    print(\"==================================================================\")\n",
        "    print('the top possible characters are :')\n",
        "    for i in range(len(names)):\n",
        "        print(names[i], '( Possibility =', probs[i], \")\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKFpV_VAaBYw"
      },
      "source": [
        "- Test predict with VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLQpHyyoqJAi"
      },
      "outputs": [],
      "source": [
        "torch.backends.cudnn.benchmark = True\n",
        "torch.cuda.empty_cache()\n",
        "vgg16_model.cuda()\n",
        "test(vgg16_model,'VGG16')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhZX10VgaG28"
      },
      "source": [
        "- Test predict with Alexnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96vi4gL-aK0p"
      },
      "outputs": [],
      "source": [
        "Alex_model.cuda()\n",
        "test(Alex_model,'Alex')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Test predict with LeNet"
      ],
      "metadata": {
        "id": "d3wqr78bu_v1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Le_model.cuda()\n",
        "test(Le_model,'Le')"
      ],
      "metadata": {
        "id": "jmSm7M5Zu_Id"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP1ao0S/+Yg0/Le2FZK0/+/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}